---
apiVersion: kjobctl.x-k8s.io/v1alpha1
kind: ApplicationProfile
metadata:
  name: ray-job-profile
  namespace: default
spec:
  supportedModes:
    - name: RayJob
      template: ray-job-template
  volumeBundles: ["ray-job-volume-bundle"]
---
apiVersion: kjobctl.x-k8s.io/v1alpha1
kind: RayJobTemplate
metadata:
  name: ray-job-template
  namespace: default
template:
  spec:
    # submissionMode specifies how RayJob submits the Ray job to the RayCluster.
    # The default value is "K8sJobMode", meaning RayJob will submit the Ray job via a submitter Kubernetes Job.
    # The alternative value is "HTTPMode", indicating that KubeRay will submit the Ray job by sending an HTTP request to the RayCluster.
    # submissionMode: "K8sJobMode"
    entrypoint: python ${ENTRYPOINT_PATH}/sample_code.py
    # shutdownAfterJobFinishes specifies whether the RayCluster should be deleted after the RayJob finishes. Default is false.
    # shutdownAfterJobFinishes: false

    # ttlSecondsAfterFinished specifies the number of seconds after which the RayCluster will be deleted after the RayJob finishes.
    # ttlSecondsAfterFinished: 10

    # activeDeadlineSeconds is the duration in seconds that the RayJob may be active before
    # KubeRay actively tries to terminate the RayJob; value must be positive integer.
    # activeDeadlineSeconds: 120

    # RuntimeEnvYAML represents the runtime environment configuration provided as a multi-line YAML string.
    # See https://docs.ray.io/en/latest/ray-core/handling-dependencies.html for details.
    # (New in KubeRay version 1.0.)
    runtimeEnvYAML: |
      pip:
        - requests==2.26.0
        - pendulum==2.1.2
      env_vars:
        counter_name: "test_counter"

    # Suspend specifies whether the RayJob controller should create a RayCluster instance.
    # If a job is applied with the suspend field set to true, the RayCluster will not be created and we will wait for the transition to false.
    # If the RayCluster is already created, it will be deleted. In the case of transition to false, a new RayCluster will be created.
    # suspend: false

    # rayClusterSpec specifies the RayCluster instance to be created by the RayJob controller.
    rayClusterSpec:
      rayVersion: '2.9.0' # should match the Ray version in the image of the containers
      # Ray head pod template
      headGroupSpec:
        # The `rayStartParams` are used to configure the `ray start` command.
        # See https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayStartParams.md for the default settings of `rayStartParams` in KubeRay.
        # See https://docs.ray.io/en/latest/cluster/cli.html#ray-start for all available options in `rayStartParams`.
        rayStartParams:
          dashboard-host: '0.0.0.0'
        #pod template
        template:
          spec:
            containers:
              - name: ray-head
                image: rayproject/ray:2.9.0
                ports:
                  - containerPort: 6379
                    name: gcs-server
                  - containerPort: 8265 # Ray dashboard
                    name: dashboard
                  - containerPort: 10001
                    name: client
                resources:
                  limits:
                    cpu: "1"
                  requests:
                    cpu: "200m"
      workerGroupSpecs:
        # the pod replicas in this group typed worker
        - replicas: 1
          minReplicas: 1
          maxReplicas: 5
          # logical group name, for this called small-group, also can be functional
          groupName: small-group
          # The `rayStartParams` are used to configure the `ray start` command.
          # See https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayStartParams.md for the default settings of `rayStartParams` in KubeRay.
          # See https://docs.ray.io/en/latest/cluster/cli.html#ray-start for all available options in `rayStartParams`.
          rayStartParams: {}
          #pod template
          template:
            spec:
              containers:
                - name: ray-worker # must consist of lower case alphanumeric characters or '-', and must start and end with an alphanumeric character (e.g. 'my-name',  or '123-abc'
                  image: rayproject/ray:2.9.0
                  lifecycle:
                    preStop:
                      exec:
                        command: [ "/bin/sh","-c","ray stop" ]
                  resources:
                    limits:
                      cpu: "1"
                    requests:
                      cpu: "200m"
---
apiVersion: kjobctl.x-k8s.io/v1alpha1
kind: VolumeBundle
metadata:
  name: ray-job-volume-bundle
  namespace: default
spec:
  volumes:
    - name: ray-job-code-sample
      configMap:
        name: ray-job-code-sample
        items:
          - key: sample_code.py
            path: sample_code.py
  containerVolumeMounts:
    - name: ray-job-code-sample
      mountPath: /home/ray/samples
  envVars:
    - name: ENTRYPOINT_PATH
      value: /home/ray/samples
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: ray-job-code-sample
  namespace: default
data:
  sample_code.py: |
    import ray
    import os
    import requests

    ray.init()

    @ray.remote
    class Counter:
        def __init__(self):
            # Used to verify runtimeEnv
            self.name = os.getenv("counter_name")
            assert self.name == "test_counter"
            self.counter = 0

        def inc(self):
            self.counter += 1

        def get_counter(self):
            return "{} got {}".format(self.name, self.counter)

    counter = Counter.remote()

    for _ in range(5):
        ray.get(counter.inc.remote())
        print(ray.get(counter.get_counter.remote()))

    # Verify that the correct runtime env was used for the job.
    assert requests.__version__ == "2.26.0"